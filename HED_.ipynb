{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLo44_37Fxg4",
        "outputId": "92d02b63-8f42-46e6-aafa-344526d11dd1"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/ashukid/hed-edge-detector/raw/refs/heads/master/hed_pretrained_bsds.caffemodel\n",
        "!wget https://github.com/ashukid/hed-edge-detector/raw/refs/heads/master/deploy.prototxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!curl -O https://github.com/ashukid/hed-edge-detector/raw/refs/heads/master/hed_pretrained_bsds.caffemodel\n",
        "!curl -O https://github.com/ashukid/hed-edge-detector/raw/refs/heads/master/deploy.prototxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JeBgWkjCEgye"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "# from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASEPATH = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M8rHFXMYGORO"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    \"image\": \"image.jpg\",\n",
        "    \"video\": \"SCARA_robot_plan-view.avi\",\n",
        "    \"edge_detector\": \"\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nw-No5TeFKbf"
      },
      "outputs": [],
      "source": [
        "class CropLayer(object):\n",
        "  def __init__(self, params, blobs):\n",
        "    # initialize our starting and ending (x, y)-coordinates of\n",
        "    # the crop\n",
        "    self.startX = 0\n",
        "    self.startY = 0\n",
        "    self.endX = 0\n",
        "    self.endY = 0\n",
        "  def getMemoryShapes(self, inputs):\n",
        "    # the crop layer will receive two inputs -- we need to crop\n",
        "    # the first input blob to match the shape of the second one,\n",
        "    # keeping the batch size and number of channels\n",
        "    (inputShape, targetShape) = (inputs[0], inputs[1])\n",
        "    (batchSize, numChannels) = (inputShape[0], inputShape[1])\n",
        "    (H, W) = (targetShape[2], targetShape[3])\n",
        "    # compute the starting and ending crop coordinates\n",
        "    self.startX = int((inputShape[3] - targetShape[3]) / 2)\n",
        "    self.startY = int((inputShape[2] - targetShape[2]) / 2)\n",
        "    self.endX = self.startX + W\n",
        "    self.endY = self.startY + H\n",
        "    # return the shape of the volume (we'll perform the actual\n",
        "    # crop during the forward pass\n",
        "    return [[batchSize, numChannels, H, W]]\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    # use the derived (x, y)-coordinates to perform the crop\n",
        "    return [inputs[0][:, :, self.startY:self.endY,\n",
        "        self.startX:self.endX]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9nHRTM_FZpn",
        "outputId": "b132d63d-e550-476d-e51c-fde69ae20242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] loading edge detector...\n"
          ]
        }
      ],
      "source": [
        "# load our serialized edge detector from disk\n",
        "print(\"[INFO] loading edge detector...\")\n",
        "protoPath = os.path.sep.join([BASEPATH, args[\"edge_detector\"],\n",
        "\t\"deploy.prototxt\"])\n",
        "modelPath = os.path.sep.join([BASEPATH, args[\"edge_detector\"],\n",
        "\t\"hed_pretrained_bsds.caffemodel\"])\n",
        "# net = cv2.dnn.readNetFromCaffe(r\"C:\\Users\\obase\\Documents\\python_script\\GRAMAI\\HED\\deploy.prototxt\", r\"C:\\Users\\obase\\Documents\\python_script\\GRAMAI\\HED\\hed_pretrained_bsds.caffemodel\")\n",
        "net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
        "# register our new layer with the model\n",
        "cv2.dnn_registerLayer(\"Crop\", CropLayer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLiSWaQnFeF0",
        "outputId": "1911c053-8e9d-4ced-d250-eae5c69f9e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] performing Canny edge detection...\n"
          ]
        }
      ],
      "source": [
        "# load the input image and grab its dimensions\n",
        "image = cv2.imread(args[\"image\"])\n",
        "(H, W) = image.shape[:2]\n",
        "# convert the image to grayscale, blur it, and perform Canny\n",
        "# edge detection\n",
        "print(\"[INFO] performing Canny edge detection...\")\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "canny = cv2.Canny(blurred, 30, 150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EsdmcxXFi9O",
        "outputId": "6fe264a4-da50-46d9-f1c6-8a944061e3eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] performing holistically-nested edge detection...\n"
          ]
        }
      ],
      "source": [
        "# construct a blob out of the input image for the Holistically-Nested\n",
        "# Edge Detector\n",
        "blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(W, H),\n",
        "\tmean=(104.00698793, 116.66876762, 122.67891434),\n",
        "\tswapRB=False, crop=False)\n",
        "# set the blob as the input to the network and perform a forward pass\n",
        "# to compute the edges\n",
        "print(\"[INFO] performing holistically-nested edge detection...\")\n",
        "net.setInput(blob)\n",
        "hed = net.forward()\n",
        "hed = cv2.resize(hed[0, 0], (W, H))\n",
        "hed = (255 * hed).astype(\"uint8\")\n",
        "# show the output edge detection results for Canny and\n",
        "# Holistically-Nested Edge Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(hed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P0UOF_2BHnes",
        "outputId": "30de1e0c-2470-42c4-f5c1-c4b4108edc1c"
      },
      "outputs": [],
      "source": [
        "cv2_imshow( image)\n",
        "cv2_imshow( canny)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky74KpNqHuuV"
      },
      "outputs": [],
      "source": [
        "hed = canny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "wcy9u9-SGyXM",
        "outputId": "c0b0d112-ef7f-4ffd-c352-e48d6a826d9a"
      },
      "outputs": [],
      "source": [
        "# prompt: generate code to perform hough circle detection on the image in variable hed\n",
        "\n",
        "# Perform Hough Circle Transform on the HED output\n",
        "# The parameters min_dist, param1, param2, min_radius, max_radius might need tuning\n",
        "# depending on the image and the expected circles.\n",
        "circles = cv2.HoughCircles(hed, cv2.HOUGH_GRADIENT, dp=1, minDist=20,\n",
        "                           param1=50, param2=30, minRadius=5, maxRadius=50)\n",
        "\n",
        "# Draw detected circles on the original image\n",
        "if circles is not None:\n",
        "    circles = np.round(circles[0, :]).astype(\"int\")\n",
        "    for (x, y, r) in circles:\n",
        "        cv2.circle(image, (x, y), r, (0, 255, 0), 4)\n",
        "        cv2.rectangle(image, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1)\n",
        "\n",
        "# Show the image with detected circles\n",
        "plt.imshow( image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNkjlhE7JIpG",
        "outputId": "c5dc26ca-77d9-41f6-8d0b-2fdb846f37bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] reading video file...\n"
          ]
        }
      ],
      "source": [
        "# prompt: generate code to read the video file SCARA_robot_plan-view.avi, read frame by frame, apply canny edge detection, use hough circle and write another video file\n",
        "\n",
        "# Read the video file\n",
        "print(\"[INFO] reading video file...\")\n",
        "cap = cv2.VideoCapture(args[\"video\"])\n",
        "\n",
        "# Get video properties for writing the output video\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter('output_video.avi', fourcc, fps, (frame_width, frame_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 364 of 365:   0%|          | 0/365 [56:06<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] video processing finished and saved as output_video.avi\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pbar = tqdm(range(total_frames),desc=\"\")\n",
        "i = 0\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret == True:\n",
        "        pbar.set_description(f\" {i} of {total_frames}\")\n",
        "        \n",
        "        # Convert frame to grayscale for Canny and Hough Circle\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply Canny edge detection\n",
        "        canny_frame = cv2.Canny(gray_frame, 30, 150)\n",
        "\n",
        "        # construct a blob out of the input frame for the Holistically-Nested\n",
        "        # Edge Detector, set the blob, and perform a forward pass to\n",
        "        # compute the edges\n",
        "        blob = cv2.dnn.blobFromImage(frame, scalefactor=1.0, size=(W, H),\n",
        "            mean=(104.00698793, 116.66876762, 122.67891434),\n",
        "            swapRB=False, crop=False)\n",
        "        net.setInput(blob)\n",
        "        hed = net.forward()\n",
        "        hed = cv2.resize(hed[0, 0], (W, H))\n",
        "        hed = (255 * hed).astype(\"uint8\")\n",
        "\n",
        "        # Perform Hough Circle Transform on the Canny output\n",
        "        # Adjust parameters as needed\n",
        "        # circles = cv2.HoughCircles(canny_frame, cv2.HOUGH_GRADIENT, dp=1, minDist=50,\n",
        "        #                            param1=100, param2=30, minRadius=4, maxRadius=55)\n",
        "        circles = cv2.HoughCircles(hed, cv2.HOUGH_GRADIENT, dp=1, minDist=50,\n",
        "                                   param1=100, param2=30, minRadius=4, maxRadius=55)        \n",
        "        # Draw detected circles on the original frame\n",
        "        if circles is not None:\n",
        "            circles = np.round(circles[0, :]).astype(\"int\")\n",
        "            for (x, y, r) in circles:\n",
        "                cv2.circle(frame, (x, y), r, (0, 255, 0), 4)\n",
        "                cv2.rectangle(frame, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1)\n",
        "\n",
        "        # Write the frame with detected circles to the output video\n",
        "        out.write(frame)\n",
        "\n",
        "        # Optional: Display the processed frame (can slow down processing)\n",
        "        # cv2_imshow(frame)\n",
        "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        #     break\n",
        "        pbar.update(1)\n",
        "        i +=1\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Release everything when job is finished\n",
        "cap.release()\n",
        "out.release()\n",
        "# cv2.destroyAllWindows()\n",
        "\n",
        "print(\"[INFO] video processing finished and saved as output_video.avi\")\n",
        "\n",
        "# Download the output video\n",
        "# files.download('output_video.avi')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mdx_robot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
